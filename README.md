This project demonstrates an **end-to-end data engineering pipeline** using **Azure Databricks**, **Azure SQL Database**, and **Azure Data Lake Storage Gen2** to process and analyze Tokyo Olympics 2020 datasets. 
The pipeline ingests raw data from CSV files stored in **Azure Data Lake**, transforms it using **PySpark** in **Databricks**, and loads the cleaned data into **Azure SQL Database**. 
Key datasets processed include **Athletes**, **Teams**, **Entries by Gender**, **Coaches**, and **Medals**
